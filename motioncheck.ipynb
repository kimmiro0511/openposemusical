{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"C:\\\\softtermp\\\\S1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints(image_path, proto_file, weights_file, threshold, model_name, BODY_PARTS):\n",
    "    global points\n",
    "\n",
    "    # 이미지 읽어오기\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    # 네트워크 불러오기\n",
    "    net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
    "\n",
    "    # 입력 이미지의 사이즈 정의\n",
    "    image_height = 368\n",
    "    image_width = 368\n",
    "\n",
    "    # 네트워크에 넣기 위한 전처리\n",
    "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (image_width, image_height), (0, 0, 0), swapRB=False,\n",
    "                                       crop=False)\n",
    "\n",
    "    # 전처리된 blob 네트워크에 입력\n",
    "    net.setInput(input_blob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    out = net.forward()\n",
    "    # The output is a 4D matrix :\n",
    "    # The first dimension being the image ID ( in case you pass more than one image to the network ).\n",
    "    # The second dimension indicates the index of a keypoint.\n",
    "    # The model produces Confidence Maps and Part Affinity maps which are all concatenated.\n",
    "    # For COCO model it consists of 57 parts – 18 keypoint confidence Maps + 1 background + 19*2 Part Affinity Maps. Similarly, for MPI, it produces 44 points.\n",
    "    # We will be using only the first few points which correspond to Keypoints.\n",
    "    # The third dimension is the height of the output map.\n",
    "    out_height = out.shape[2]\n",
    "    # The fourth dimension is the width of the output map.\n",
    "    out_width = out.shape[3]\n",
    "\n",
    "    # 원본 이미지의 높이, 너비를 받아오기\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # 포인트 리스트 초기화\n",
    "    points = []\n",
    "\n",
    "    print(f\"\\n========== {model_name} ==========\")\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "\n",
    "        # 신체 부위의 confidence map\n",
    "        prob_map = out[0, i, :, :]\n",
    "\n",
    "        # 최소값, 최대값, 최소값 위치, 최대값 위치\n",
    "        min_val, prob, min_loc, point = cv2.minMaxLoc(prob_map)\n",
    "\n",
    "        # 원본 이미지에 맞게 포인트 위치 조정\n",
    "        x = (frame_width * point[0]) / out_width\n",
    "        x = int(x)\n",
    "        y = (frame_height * point[1]) / out_height\n",
    "        y = int(y)\n",
    "\n",
    "        if prob > threshold:  # [pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append((x, y))\n",
    "            # print(f\"[pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "        else:  # [not pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append(None)\n",
    "            # print(f\"[not pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_keypoints_with_lines(POSE_PAIRS, frame):\n",
    "\n",
    "    # 프레임 복사\n",
    "    frame_line = frame.copy()\n",
    "    \n",
    "    # Neck 과 MidHeap 의 좌표값이 존재한다면\n",
    "    if (points[1] is not None) and (points[8] is not None):\n",
    "    \tcalculate_degree(point_1=points[1], point_2=points[8], frame=frame_line)\n",
    "    \n",
    "    for pair in POSE_PAIRS:\n",
    "        part_a = pair[0]  # 0 (Head)\n",
    "        part_b = pair[1]  # 1 (Neck)\n",
    "        if points[part_a] and points[part_b]:\n",
    "            print(f\"[linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "            # Neck 과 MidHip 이라면 분홍색 선\n",
    "            if part_a == 1 and part_b == 8:\n",
    "                cv2.line(frame, points[part_a], points[part_b], (255, 0, 255), 3)\n",
    "            else:  # 노란색 선\n",
    "                cv2.line(frame, points[part_a], points[part_b], (0, 255, 0), 3)\n",
    "        else:\n",
    "            print(f\"[not linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "    \n",
    "    # 포인팅 되어있는 프레임과 라인까지 연결된 프레임을 가로로 연결\n",
    "    frame_horizontal = cv2.hconcat([frame, frame_line])\n",
    "    cv2.imshow(\"Output_Keypoints_With_Lines\", frame_horizontal)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_degree(point_1, point_2, frame):\n",
    "    # 역탄젠트 구하기\n",
    "    dx = point_2[0] - point_1[0]\n",
    "    dy = point_2[1] - point_1[1]\n",
    "    rad = math.atan2(abs(dy), abs(dx))\n",
    "\n",
    "    # radian 을 degree 로 변환\n",
    "    deg = rad * 180 / math.pi\n",
    "\n",
    "    # degree 가 45'보다 작으면 허리가 숙여졌다고 판단\n",
    "    if deg < 45:\n",
    "        string = \"Bend Down\"\n",
    "        cv2.putText(frame, string, (0, 25), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 255))\n",
    "        print(f\"[degree] {deg} ({string})\")\n",
    "    else:\n",
    "        string = \"Stand\"\n",
    "        cv2.putText(frame, string, (0, 25), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 255))\n",
    "        print(f\"[degree] {deg} ({string})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'protoFile_body_25' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e42b61362e7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     frame_man = output_keypoints(image_path=path, proto_file=protoFile_body_25, weights_file=weightsFile_body_25,\n\u001b[0m\u001b[0;32m     29\u001b[0m                                  threshold=0.1, model_name=path.split('\\\\')[-1], BODY_PARTS=BODY_PARTS_BODY_25)\n\u001b[0;32m     30\u001b[0m     \u001b[0moutput_keypoints_with_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPOSE_PAIRS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPOSE_PAIRS_BODY_25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframe_man\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'protoFile_body_25' is not defined"
     ]
    }
   ],
   "source": [
    "BODY_PARTS_BODY_25 = {0: \"Nose\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                      5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"MidHip\", 9: \"RHip\",\n",
    "                      10: \"RKnee\", 11: \"RAnkle\", 12: \"LHip\", 13: \"LKnee\", 14: \"LAnkle\",\n",
    "                      15: \"REye\", 16: \"LEye\", 17: \"REar\", 18: \"LEar\", 19: \"LBigToe\",\n",
    "                      20: \"LSmallToe\", 21: \"LHeel\", 22: \"RBigToe\", 23: \"RSmallToe\", 24: \"RHeel\", 25: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_BODY_25 = [[0, 1], [0, 15], [0, 16], [1, 2], [1, 5], [1, 8], [8, 9], [8, 12], [9, 10], [12, 13], [2, 3],\n",
    "                      [3, 4], [5, 6], [6, 7], [10, 11], [13, 14], [15, 17], [16, 18], [14, 21], [19, 21], [20, 21],\n",
    "                      [11, 24], [22, 24], [23, 24]]\n",
    "\n",
    "# 각 파일 path\n",
    "protoFile = \"C:\\\\softtermp\\\\openpose-master\\\\openpose-master\\\\models\\\\pose\\\\mpi\\\\pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"C:\\\\softtermp\\\\openpose-master\\\\openpose-master\\\\models\\\\pose\\\\mpi\\\\pose_iter_160000.caffemodel\"\n",
    " \n",
    "# 이미지 경로 (출처: https://www.nongmin.com/plan/PLN/SRS/246508/view)\n",
    "path_list = []\n",
    "walk_1 = \"C:\\\\Users\\\\user\\\\Pictures\\\\Saved Pictures\\\\sample_image\\\\man_walk_1.jpg\"\n",
    "walk_2 = \"C:\\\\Users\\\\user\\\\Pictures\\\\Saved Pictures\\\\sample_image\\\\man_walk_2.jpg\"\n",
    "stand = \"C:\\\\Users\\\\user\\\\Pictures\\\\Saved Pictures\\\\sample_image\\\\man_stand.jpg\"\n",
    "sit = \"C:\\\\Users\\\\user\\\\Pictures\\\\Saved Pictures\\\\sample_image\\\\man_sit.jpg\"\n",
    "down = \"C:\\\\Users\\\\user\\\\Pictures\\\\Saved Pictures\\\\sample_image\\\\man_down.jpg\"\n",
    "path_list.extend([walk_1, walk_2, stand, sit, down])\n",
    "\n",
    "# 키포인트를 저장할 빈 리스트\n",
    "points = []\n",
    "\n",
    "for path in path_list:\n",
    "    frame_man = output_keypoints(image_path=path, proto_file=protoFile_body_25, weights_file=weightsFile_body_25,\n",
    "                                 threshold=0.1, model_name=path.split('\\\\')[-1], BODY_PARTS=BODY_PARTS_BODY_25)\n",
    "    output_keypoints_with_lines(POSE_PAIRS=POSE_PAIRS_BODY_25, frame=frame_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
